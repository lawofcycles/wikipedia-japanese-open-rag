from typing import AsyncGenerator
import asyncio
import gradio as gr

from model_vllm import get_input_token_length, run

DEFAULT_SYSTEM_PROMPT = 'ã‚ãªãŸã¯èª å®Ÿã§å„ªç§€ãªæ—¥æœ¬äººã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚'
MAX_MAX_NEW_TOKENS = 2048
DEFAULT_MAX_NEW_TOKENS = 512
MAX_INPUT_TOKEN_LENGTH = 4000

TITLE = '# ELYZA-japanese-Llama-2-13b-instruct'

def clear_and_save_textbox(message: str) -> tuple[str, str]:
    return '', message


def display_input(message: str, history: list[tuple[str, str]]) -> list[tuple[str, str]]:
    history.append((message, ''))
    return history


def delete_prev_fn(history: list[tuple[str, str]]) -> tuple[list[tuple[str, str]], str]:
    try:
        message, _ = history.pop()
    except IndexError:
        message = ''
    return history, message or ''


async def generate(
    message: str,
    history_with_input: list[tuple[str, str]],
    system_prompt: str,
    max_new_tokens: int,
    temperature: float,
    top_p: float,
    top_k: int,
    do_sample: bool,
    repetition_penalty: float,
) -> AsyncGenerator[list[tuple[str, str]], None]:
    if max_new_tokens > MAX_MAX_NEW_TOKENS:
        raise ValueError

    history = history_with_input[:-1]
    stream = await run(
        message=message,
        chat_history=history,
        system_prompt=system_prompt,
        max_new_tokens=max_new_tokens,
        temperature=float(temperature),
        top_p=float(top_p),
        top_k=top_k,
        do_sample=do_sample,
        repetition_penalty=float(repetition_penalty),
        stream=True,
    )
    async for response in stream:
        yield history + [(message, response)]


def process_example(message: str) -> tuple[str, list[tuple[str, str]]]:
    response = asyncio.run(run(
        message=message,
        chat_history=[],
        system_prompt=DEFAULT_SYSTEM_PROMPT,
        max_new_tokens=DEFAULT_MAX_NEW_TOKENS,
        temperature=1,
        top_p=0.95,
        top_k=50,
        do_sample=False,
        repetition_penalty=1.0,
        stream=False
    ))

    return '', [(message, response)]

def check_input_token_length(message: str, chat_history: list[tuple[str, str]], system_prompt: str) -> None:
    input_token_length = get_input_token_length(message, chat_history, system_prompt)
    if input_token_length > MAX_INPUT_TOKEN_LENGTH:
        raise gr.Error(
            f'åˆè¨ˆå¯¾è©±é•·ãŒé•·ã™ãã¾ã™ ({input_token_length} > {MAX_INPUT_TOKEN_LENGTH})ã€‚å…¥åŠ›æ–‡ç« ã‚’çŸ­ãã™ã‚‹ã‹ã€ã€ŒğŸ—‘ï¸  ã“ã‚Œã¾ã§ã®å‡ºåŠ›ã‚’æ¶ˆã™ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚'
        )

    if len(message) <= 0:
        raise gr.Error('å…¥åŠ›ãŒç©ºã§ã™ã€‚1æ–‡å­—ä»¥ä¸Šã®æ–‡å­—åˆ—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚')


def convert_history_to_str(history: list[tuple[str, str]]) -> str:
    res = []
    for user_utt, sys_utt in history:
        res.append(f'ğŸ˜ƒ: {user_utt}')
        res.append(f'ğŸ¤–: {sys_utt}')
    return '<br>'.join(res)


with gr.Blocks(css='style.css') as demo:
    gr.Markdown(TITLE)
    with gr.Group():
        chatbot = gr.Chatbot(
            label='Chatbot',
            height=600,
        )
        with gr.Column():
            textbox = gr.Textbox(
                container=False,
                show_label=False,
                placeholder='æŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ä¾‹: ã‚«ãƒ¬ãƒ¼ã¨ãƒãƒ³ãƒãƒ¼ã‚°ã‚’çµ„ã¿åˆã‚ã›ãŸç¾å‘³ã—ã„æ–™ç†ã‚’3ã¤æ•™ãˆã¦',
                scale=10,
                lines=10,
            )
            submit_button = gr.Button(
                'ä»¥ä¸‹ã®èª¬æ˜æ–‡ãƒ»å…è²¬äº‹é …ãƒ»ãƒ‡ãƒ¼ã‚¿åˆ©ç”¨ã«åŒæ„ã—ã¦é€ä¿¡', variant='primary', scale=1, min_width=0
            )
    with gr.Row():
        retry_button = gr.Button('ğŸ”„  åŒã˜å…¥åŠ›ã§ã‚‚ã†ä¸€åº¦ç”Ÿæˆ', variant='secondary')
        undo_button = gr.Button('â†©ï¸ ã²ã¨ã¤å‰ã®çŠ¶æ…‹ã«æˆ»ã‚‹', variant='secondary')
        clear_button = gr.Button('ğŸ—‘ï¸  ã“ã‚Œã¾ã§ã®å‡ºåŠ›ã‚’æ¶ˆã™', variant='secondary')

    saved_input = gr.State()
    uuid_list = gr.State([])

    with gr.Accordion(label='ä¸Šã®å¯¾è©±å±¥æ­´ã‚’ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆç”¨ã«æ•´å½¢', open=False):
        output_textbox = gr.Markdown()

    with gr.Accordion(label='è©³ç´°è¨­å®š', open=False):
        system_prompt = gr.Textbox(label='ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ', value=DEFAULT_SYSTEM_PROMPT, lines=8)
        max_new_tokens = gr.Slider(
            label='æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°',
            minimum=1,
            maximum=MAX_MAX_NEW_TOKENS,
            step=1,
            value=DEFAULT_MAX_NEW_TOKENS,
        )
        repetition_penalty = gr.Slider(
            label='Repetition penalty',
            minimum=1.0,
            maximum=10.0,
            step=0.1,
            value=1.0,
        )
        do_sample = gr.Checkbox(label='do_sample', value=False)
        temperature = gr.Slider(
            label='Temperature',
            minimum=0.1,
            maximum=4.0,
            step=0.1,
            value=1.0,
        )
        top_p = gr.Slider(
            label='Top-p (nucleus sampling)',
            minimum=0.05,
            maximum=1.0,
            step=0.05,
            value=0.95,
        )
        top_k = gr.Slider(
            label='Top-k',
            minimum=1,
            maximum=1000,
            step=1,
            value=50,
        )

    textbox.submit(
        fn=clear_and_save_textbox,
        inputs=textbox,
        outputs=[textbox, saved_input],
        api_name=False,
        queue=False,
    ).then(
        fn=check_input_token_length,
        inputs=[saved_input, chatbot, system_prompt],
        api_name=False,
        queue=False,
    ).success(
        fn=display_input,
        inputs=[saved_input, chatbot],
        outputs=chatbot,
        api_name=False,
        queue=False,
    ).then(
        fn=generate,
        inputs=[
            saved_input,
            chatbot,
            system_prompt,
            max_new_tokens,
            temperature,
            top_p,
            top_k,
            do_sample,
            repetition_penalty,
        ],
        outputs=chatbot,
        api_name=False,
    ).then(
        fn=convert_history_to_str,
        inputs=chatbot,
        outputs=output_textbox,
    )

    button_event_preprocess = (
        submit_button.click(
            fn=clear_and_save_textbox,
            inputs=textbox,
            outputs=[textbox, saved_input],
            api_name=False,
            queue=False,
        )
        .then(
            fn=check_input_token_length,
            inputs=[saved_input, chatbot, system_prompt],
            api_name=False,
            queue=False,
        )
        .success(
            fn=display_input,
            inputs=[saved_input, chatbot],
            outputs=chatbot,
            api_name=False,
            queue=False,
        ).success(
            fn=generate,
            inputs=[
                saved_input,
                chatbot,
                system_prompt,
                max_new_tokens,
                temperature,
                top_p,
                top_k,
                do_sample,
                repetition_penalty,
            ],
            outputs=chatbot,
            api_name=False,
        )
        .then(
            fn=convert_history_to_str,
            inputs=chatbot,
            outputs=output_textbox,
        )
    )

    retry_button.click(
        fn=delete_prev_fn,
        inputs=chatbot,
        outputs=[chatbot, saved_input],
        api_name=False,
        queue=False,
    ).then(
        fn=check_input_token_length,
        inputs=[saved_input, chatbot, system_prompt],
        api_name=False,
        queue=False,
    ).success(
        fn=display_input,
        inputs=[saved_input, chatbot],
        outputs=chatbot,
        api_name=False,
        queue=False,
    ).then(
        fn=generate,
        inputs=[
            saved_input,
            chatbot,
            system_prompt,
            max_new_tokens,
            temperature,
            top_p,
            top_k,
            do_sample,
            repetition_penalty,
        ],
        outputs=chatbot,
        api_name=False,
    ).then(
        fn=convert_history_to_str,
        inputs=chatbot,
        outputs=output_textbox,
    )

    undo_button.click(
        fn=delete_prev_fn,
        inputs=chatbot,
        outputs=[chatbot, saved_input],
        api_name=False,
        queue=False,
    ).then(
        fn=lambda x: x,
        inputs=saved_input,
        outputs=textbox,
        api_name=False,
        queue=False,
    ).then(
        fn=convert_history_to_str,
        inputs=chatbot,
        outputs=output_textbox,
    )

    clear_button.click(
        fn=lambda: ([], ''),
        outputs=[chatbot, saved_input],
        queue=False,
        api_name=False,
    ).then(
        fn=convert_history_to_str,
        inputs=chatbot,
        outputs=output_textbox,
    )

demo.queue(max_size=5).launch(server_name='0.0.0.0')